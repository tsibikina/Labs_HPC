# Лабораторная работа 1: Перемножение матриц

## Задача
Реализовать алгоритм перемножения матриц на языке Python с использованием CUDA для ускорения вычислений.

## Входные данные
Две матрицы размером от 100x100 до 2000x2000 каждая.

## Выходные данные
- Проверка корректности перемножения.
- Время вычисления.

## Реализация
В проекте реализованы две функции для перемножения матриц:
1. **На CPU**: Используется функция numpy_matrix_multiplication(A, B, m, n, p), которая применяет встроенную функцию np.matmul для выполнения умножения матриц на CPU.
2. **На GPU**: Используется CUDA-ядро matmul_cuda, реализованное с помощью cupy.RawKernel, что позволяет напрямую управлять вычислениями на GPU.

## Результаты
Умножение матриц на CUDA было распараллелено на уровне потоков, где каждый поток вычисляет один элемент результирующей матрицы C. Это значительно ускоряет вычисления, так как множество потоков могут работать одновременно.

В то время как NumPy выполняет умножение матриц на CPU, распараллеливание ограничено количеством ядер процессора.

### Сравнение производительности
Как видно из таблицы и графика, CUDA значительно превосходит NumPy по скорости выполнения умножения матриц. Ускорение составляет примерно 3.70 раз для всех размеров матриц. Это объясняется тем, что GPU имеет гораздо большее количество вычислительных блоков, чем CPU, что позволяет эффективно распараллеливать вычисления.

## Выводы
В данной лабораторной работе было проведено сравнение производительности умножения матриц на CUDA и NumPy. Результаты показали, что использование CUDA для умножения матриц значительно ускоряет вычисления по сравнению с традиционным подходом на CPU с использованием NumPy. Это объясняется эффективным распараллеливанием вычислений на GPU, которое позволяет использовать множество вычислительных блоков для одновременного выполнения задач.

Таким образом, для задач, требующих интенсивных вычислений с матрицами, использование CUDA является предпочтительным решением, обеспечивающим значительное ускорение выполнения.
